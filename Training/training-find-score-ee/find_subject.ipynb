{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42f5bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported:\n",
      "  üß™ scaler: C:\\Users\\vuman\\Desktop\\AI_Project\\Final in HUST\\Project\\training-find-score-ee\\2\\scaler.joblib\n",
      "  üìú subjects: C:\\Users\\vuman\\Desktop\\AI_Project\\Final in HUST\\Project\\training-find-score-ee\\3\\subjects.json\n",
      "  (#subjects = 26)\n"
     ]
    }
   ],
   "source": [
    "# ==== EXPORT SUBJECTS & SCALER (no model training) ====\n",
    "from pathlib import Path\n",
    "import json, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Config (gi·ªØ nguy√™n nh∆∞ b·∫°n ƒëang d√πng) ----\n",
    "DATA_XLSX   = Path(\"Data_clean/Data_subject_complete.xlsx\")  # c√≥ c·ªôt 'split'\n",
    "SCALER_PATH = Path(\"2/scaler.joblib\")                        # n∆°i l∆∞u scaler\n",
    "SUBJECTS_JSON = Path(\"3/subjects.json\")                      # n∆°i l∆∞u danh s√°ch m√¥n\n",
    "\n",
    "# ---- Load data ----\n",
    "df = pd.read_excel(DATA_XLSX)\n",
    "\n",
    "# L·∫•y c√°c c·ªôt s·ªë l√†m \"subjects\"\n",
    "subject_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if not subject_cols:\n",
    "    raise ValueError(\"Kh√¥ng t√¨m th·∫•y c·ªôt s·ªë n√†o trong file d·ªØ li·ªáu. H√£y ki·ªÉm tra DATA_XLSX.\")\n",
    "\n",
    "# Ch·ªâ d√πng TRAIN ƒë·ªÉ t√≠nh scaler (best practice)\n",
    "if \"split\" not in df.columns:\n",
    "    raise ValueError(\"Thi·∫øu c·ªôt 'split' trong d·ªØ li·ªáu. C·∫ßn c√≥ ƒë·ªÉ t√°ch train/val/test.\")\n",
    "df_tr = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "if df_tr.empty:\n",
    "    raise ValueError(\"T·∫≠p TRAIN r·ªóng. H√£y ki·ªÉm tra gi√° tr·ªã c·ªôt 'split'.\")\n",
    "\n",
    "# ---- Compute z-score stats theo TRAIN ----\n",
    "train_means = df_tr[subject_cols].mean(axis=0)\n",
    "train_stds  = df_tr[subject_cols].std(axis=0).replace(0, 1.0)  # tr√°nh chia cho 0\n",
    "\n",
    "# ---- Save artifacts ----\n",
    "SCALER_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(SUBJECTS_JSON).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump({\"means\": train_means.to_dict(), \"stds\": train_stds.to_dict()}, SCALER_PATH)\n",
    "Path(SUBJECTS_JSON).write_text(json.dumps(subject_cols, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úÖ Exported:\")\n",
    "print(\"  üß™ scaler:\", SCALER_PATH.resolve())\n",
    "print(\"  üìú subjects:\", Path(SUBJECTS_JSON).resolve())\n",
    "print(f\"  (#subjects = {len(subject_cols)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc106b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved GGM to: C:\\Users\\vuman\\Desktop\\AI_Project\\Final in HUST\\Project\\training-find-score-ee\\models_streamlit\\EE2_ggm.joblib\n"
     ]
    }
   ],
   "source": [
    "# Cell A ‚Äî Train GGM (Ledoit-Wolf / GraphicalLassoCV) & export\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib, json\n",
    "\n",
    "from sklearn.covariance import LedoitWolf  # nhanh, ·ªïn ƒë·ªãnh\n",
    "# from sklearn.covariance import GraphicalLassoCV  # n·∫øu mu·ªën sparse graph\n",
    "\n",
    "DATA_XLSX  = Path(\"Data_clean/Data_subject_complete.xlsx\")   # c√≥ 'split'\n",
    "SCALER_P   = Path(\"2/scaler.joblib\")                         \n",
    "SUBJECTS_P = Path(\"3/subjects.json\")                         \n",
    "OUT_GGM    = Path(\"models_streamlit/EE2_ggm.joblib\")\n",
    "\n",
    "# Load data + artifacts\n",
    "df        = pd.read_excel(DATA_XLSX)\n",
    "subjects  = json.loads(Path(SUBJECTS_P).read_text(encoding=\"utf-8\"))\n",
    "scaler    = joblib.load(SCALER_P)\n",
    "means     = pd.Series(scaler[\"means\"])\n",
    "stds      = pd.Series(scaler[\"stds\"]).replace(0, 1.0)\n",
    "\n",
    "# L·∫•y TRAIN v√† z-score\n",
    "df_tr = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "X_tr  = df_tr[subjects].copy()\n",
    "X_std = (X_tr - means) / stds\n",
    "X_std = X_std.fillna(0.0).values  # ƒëi·ªÅn mean=0 sau z-score\n",
    "\n",
    "# ∆Ø·ªõc l∆∞·ª£ng covariance\n",
    "# C√°ch 1: LedoitWolf (khuy·∫øn ngh·ªã, nhanh)\n",
    "est = LedoitWolf().fit(X_std)\n",
    "cov = est.covariance_\n",
    "\n",
    "# (Tu·ª≥ ch·ªçn) C√°ch 2: GraphicalLassoCV (ch·∫≠m h∆°n, ra precision th∆∞a)\n",
    "# est = GraphicalLassoCV().fit(X_std)\n",
    "# cov = est.covariance_\n",
    "# precision = est.precision_\n",
    "\n",
    "# L∆∞u artifacts\n",
    "OUT_GGM.parent.mkdir(parents=True, exist_ok=True)\n",
    "ggm_art = {\n",
    "    \"cov\": cov,                    # ƒë·ªß ƒë·ªÉ l√†m conditional prediction\n",
    "    # \"precision\": precision,      # n·∫øu d√πng GraphicalLassoCV\n",
    "    \"subjects\": subjects,\n",
    "    \"train_means\": means.to_dict(),\n",
    "    \"train_stds\": stds.to_dict(),\n",
    "}\n",
    "joblib.dump(ggm_art, OUT_GGM)\n",
    "print(\"‚úÖ Saved GGM to:\", OUT_GGM.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
