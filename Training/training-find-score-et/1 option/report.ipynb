{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Imports & Paths\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib, json, re\n",
    "\n",
    "# === Paths (giữ đúng như bạn đã dùng) ===\n",
    "DATA_XLSX  = Path(\"Data_clean/Data_subject_complete.xlsx\")   # có cột 'split'\n",
    "SCALER_P   = Path(\"2/scaler.joblib\")\n",
    "SUBJECTS_P = Path(\"3/subjects.json\")\n",
    "INDEX_CSV  = Path(\"1/index.csv\")\n",
    "MF_PATH    = Path(\"models_streamlit_mf/index.csv/find-subject-score.joblib\")\n",
    "\n",
    "OUTPUT_XLSX = Path(\"eval_metrics.xlsx\")\n",
    "\n",
    "print(\"✅ Paths ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef74103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Load artifacts\n",
    "subjects = json.loads(SUBJECTS_P.read_text(encoding=\"utf-8\"))\n",
    "scaler   = joblib.load(SCALER_P)\n",
    "means = pd.Series(scaler[\"means\"])\n",
    "stds  = pd.Series(scaler[\"stds\"]).replace(0, 1.0)\n",
    "\n",
    "# XGB index (target,K -> model_path)\n",
    "if INDEX_CSV.exists():\n",
    "    xgb_index = pd.read_csv(INDEX_CSV)\n",
    "else:\n",
    "    xgb_index = pd.DataFrame(columns=[\"target\",\"K\",\"model_path\"])\n",
    "\n",
    "# MF artifacts (optional fallback)\n",
    "mf_art = joblib.load(MF_PATH) if MF_PATH.exists() else None\n",
    "\n",
    "col_index = {s:i for i,s in enumerate(subjects)}\n",
    "print(f\"✅ Loaded subjects={len(subjects)} | scaler | xgb_index rows={len(xgb_index)} | mf={'yes' if mf_art is not None else 'no'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Helpers\n",
    "def safe_name(text: str) -> str:\n",
    "    return re.sub(r'[\\\\/:\\\"*?<>| ]+', \"_\", str(text)).strip(\"_\").lower()\n",
    "\n",
    "def standardize_user_row(user_numeric: dict):\n",
    "    # user_numeric: {subject -> numeric GPA}\n",
    "    vals = []\n",
    "    for s in subjects:\n",
    "        v = user_numeric.get(s, np.nan)\n",
    "        if pd.isna(v): vals.append(np.nan)\n",
    "        else:          vals.append((float(v) - means[s]) / stds[s])\n",
    "    return np.array(vals, dtype=float)\n",
    "\n",
    "def build_masked_features(std_row: np.ndarray, kept_subjects: list, add_missing=True):\n",
    "    vals = std_row.copy()\n",
    "    mk = np.zeros_like(vals, dtype=bool)\n",
    "    for s in kept_subjects:\n",
    "        j = col_index.get(s)\n",
    "        if j is not None: mk[j] = True\n",
    "    vals[~mk] = np.nan\n",
    "    if add_missing:\n",
    "        miss = (~np.isfinite(vals)).astype(float)\n",
    "    vals = np.nan_to_num(vals, nan=0.0)\n",
    "    return np.concatenate([vals, miss], axis=0) if add_missing else vals\n",
    "\n",
    "def select_xgb_model_path(target: str, K: int):\n",
    "    df = xgb_index[xgb_index[\"target\"] == target]\n",
    "    if df.empty:\n",
    "        return None\n",
    "    if (df[\"K\"] == K).any():\n",
    "        return Path(df[df[\"K\"] == K][\"model_path\"].iloc[0])\n",
    "    # K gần nhất\n",
    "    df2 = df.assign(diff=(df[\"K\"] - K).abs()).sort_values(\"diff\")\n",
    "    return Path(df2.iloc[0][\"model_path\"])\n",
    "\n",
    "def predict_mf_for_target(user_numeric: dict, target: str):\n",
    "    if mf_art is None: return np.nan\n",
    "    V   = mf_art[\"V\"]        # [n_items, k]\n",
    "    b_i = mf_art[\"b_item\"]   # [n_items]\n",
    "    mu  = mf_art[\"mu\"]\n",
    "    lam = mf_art[\"lambda\"]\n",
    "    k   = mf_art[\"k\"]\n",
    "    # standardize user\n",
    "    std_vals = []\n",
    "    for s in subjects:\n",
    "        v = user_numeric.get(s, np.nan)\n",
    "        if pd.isna(v):\n",
    "            std_vals.append(np.nan)\n",
    "        else:\n",
    "            std_vals.append((float(v) - means[s]) / stds[s])\n",
    "    std_vals = np.array(std_vals, dtype=float)\n",
    "\n",
    "    obs_idx = np.where(np.isfinite(std_vals))[0]\n",
    "    if obs_idx.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    V_K = V[obs_idx]\n",
    "    r   = std_vals[obs_idx]\n",
    "    rhs = r - mu - b_i[obs_idx]\n",
    "    A = V_K.T @ V_K + lam * np.eye(k)\n",
    "    try:\n",
    "        u_user = np.linalg.solve(A, V_K.T @ rhs)\n",
    "    except np.linalg.LinAlgError:\n",
    "        u_user = np.linalg.pinv(A) @ (V_K.T @ rhs)\n",
    "\n",
    "    t_idx = col_index[target]\n",
    "    y_std = mu + b_i[t_idx] + u_user @ V[t_idx]\n",
    "    y     = y_std * stds[target] + means[target]\n",
    "    return float(y)\n",
    "\n",
    "def hybrid_predict_row_target(user_numeric: dict, target: str):\n",
    "    \"\"\"\n",
    "    Trả về (pred, info_dict)\n",
    "    \"\"\"\n",
    "    # K: số môn có điểm (trừ target)\n",
    "    kept_subjects = [s for s in subjects if (s != target) and pd.notna(user_numeric.get(s, np.nan))]\n",
    "    K = len(kept_subjects)\n",
    "    if K < 5:\n",
    "        return np.nan, {\"reason\": f\"K={K}<5\"}\n",
    "\n",
    "    # build feature cho XGB (chuẩn hoá + mask + indicators)\n",
    "    std_row = standardize_user_row(user_numeric)\n",
    "    feats = build_masked_features(std_row, kept_subjects, add_missing=True).reshape(1, -1)\n",
    "\n",
    "    # XGB\n",
    "    pred_xgb = np.nan\n",
    "    model_path = select_xgb_model_path(target, K)\n",
    "    if model_path is not None and model_path.exists():\n",
    "        try:\n",
    "            model = joblib.load(model_path)\n",
    "            y_std = float(model.predict(feats)[0])\n",
    "            pred_xgb = y_std * stds[target] + means[target]\n",
    "        except Exception:\n",
    "            pred_xgb = np.nan\n",
    "\n",
    "    # MF\n",
    "    pred_mf = predict_mf_for_target(user_numeric, target)\n",
    "\n",
    "    # blend (giống app)\n",
    "    if np.isfinite(pred_xgb) and np.isfinite(pred_mf):\n",
    "        w = 0.85 if K <= 10 else 0.70\n",
    "        pred = w * pred_xgb + (1 - w) * pred_mf\n",
    "        src = f\"blend({w:.2f})\"\n",
    "    elif np.isfinite(pred_xgb):\n",
    "        pred = pred_xgb\n",
    "        src = \"xgb-only\"\n",
    "    elif np.isfinite(pred_mf):\n",
    "        pred = pred_mf\n",
    "        src = \"mf-only\"\n",
    "    else:\n",
    "        pred = np.nan\n",
    "        src = \"none\"\n",
    "\n",
    "    return pred, {\"K\": K, \"src\": src, \"xgb\": pred_xgb, \"mf\": pred_mf, \"model_path\": str(model_path) if model_path else None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ba9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Load dataset & split\n",
    "df = pd.read_excel(DATA_XLSX)\n",
    "assert \"split\" in df.columns, \"Thiếu cột 'split' trong dữ liệu.\"\n",
    "\n",
    "df_val  = df[df[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "df_test = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "print(f\"Rows: val={len(df_val)} | test={len(df_test)} | subjects={len(subjects)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68698dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Eval loop\n",
    "def row_to_user_numeric(row) -> dict:\n",
    "    d = {}\n",
    "    for s in subjects:\n",
    "        v = row.get(s, np.nan)\n",
    "        d[s] = np.nan if pd.isna(v) else float(v)\n",
    "    return d\n",
    "\n",
    "records = []  # split, row_id, target, y_true, y_pred, K, src\n",
    "\n",
    "for split_name, df_part in [(\"val\", df_val), (\"test\", df_test)]:\n",
    "    for i, row in df_part.iterrows():\n",
    "        user_numeric = row_to_user_numeric(row)\n",
    "        # Dự đoán cho từng target (khi có y_true)\n",
    "        for target in subjects:\n",
    "            y_true = row.get(target, np.nan)\n",
    "            if pd.isna(y_true): \n",
    "                continue\n",
    "            pred, info = hybrid_predict_row_target(user_numeric, target)\n",
    "            records.append({\n",
    "                \"split\": split_name,\n",
    "                \"row_id\": int(i),\n",
    "                \"target\": target,\n",
    "                \"y_true\": float(y_true),\n",
    "                \"y_pred\": float(pred) if np.isfinite(pred) else np.nan,\n",
    "                \"K\": info.get(\"K\", None),\n",
    "                \"src\": info.get(\"src\", None),\n",
    "                \"pred_xgb\": info.get(\"xgb\", np.nan),\n",
    "                \"pred_mf\": info.get(\"mf\", np.nan),\n",
    "                \"model_path\": info.get(\"model_path\", None),\n",
    "            })\n",
    "\n",
    "pred_df = pd.DataFrame(records)\n",
    "print(f\"Done predictions: {len(pred_df)} rows\")\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05150f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Metrics & export\n",
    "def compute_metrics(g: pd.DataFrame):\n",
    "    g = g.dropna(subset=[\"y_true\", \"y_pred\"]).copy()\n",
    "    if len(g) == 0:\n",
    "        return pd.Series({\"n\": 0, \"mse\": np.nan, \"rmse\": np.nan, \"mae\": np.nan, \"r2\": np.nan})\n",
    "    y = g[\"y_true\"].values\n",
    "    p = g[\"y_pred\"].values\n",
    "    mse  = float(np.mean((y - p)**2))\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    mae  = float(np.mean(np.abs(y - p)))\n",
    "    # R^2\n",
    "    ss_res = np.sum((y - p)**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    r2 = float(1 - ss_res/ss_tot) if ss_tot > 0 else np.nan\n",
    "    return pd.Series({\"n\": len(g), \"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "# per-target per-split\n",
    "per_target_split = pred_df.groupby([\"split\",\"target\"]).apply(compute_metrics).reset_index()\n",
    "\n",
    "# overall per-split\n",
    "overall_split = pred_df.groupby(\"split\").apply(compute_metrics).reset_index()\n",
    "\n",
    "# overall (val+test)\n",
    "overall_all = compute_metrics(pred_df)\n",
    "overall_all = pd.DataFrame([overall_all])\n",
    "overall_all.insert(0, \"split\", \"val+test\")\n",
    "\n",
    "# optional: phân tích theo nguồn src (xgb-only, mf-only, blend)\n",
    "by_src_split = pred_df.groupby([\"split\",\"src\"]).apply(compute_metrics).reset_index()\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"xlsxwriter\") as writer:\n",
    "    pred_df.to_excel(writer, index=False, sheet_name=\"predictions_raw\")\n",
    "    per_target_split.to_excel(writer, index=False, sheet_name=\"metrics_per_target\")\n",
    "    overall_split.to_excel(writer, index=False, sheet_name=\"metrics_per_split\")\n",
    "    overall_all.to_excel(writer, index=False, sheet_name=\"metrics_overall\")\n",
    "    by_src_split.to_excel(writer, index=False, sheet_name=\"metrics_by_src\")\n",
    "\n",
    "print(f\"✅ Saved metrics to: {OUTPUT_XLSX.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
